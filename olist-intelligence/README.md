# Olist Intelligence Suite
[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://zero2end-ml-bootcamp.streamlit.app/)

Brezilya'nÄ±n en bÃ¼yÃ¼k e-ticaret platformu Olist'in verilerini kullanarak geliÅŸtirilmiÅŸ uÃ§tan uca Veri Bilimi ve Ä°ÅŸ ZekasÄ± Ã§Ã¶zÃ¼mÃ¼.

Brezilya'nÄ±n en bÃ¼yÃ¼k e-ticaret platformu Olist'in verilerini kullanarak geliÅŸtirilmiÅŸ uÃ§tan uca Veri Bilimi ve Ä°ÅŸ ZekasÄ± Ã§Ã¶zÃ¼mÃ¼.

> [!NOTE]
> Bu proje, **Miuul Data Science Bootcamp** bitirme projesi kapsamÄ±nda verilen talimatlara uygun olarak hazÄ±rlanmÄ±ÅŸtÄ±r.
> ğŸ“„ [Bootcamp Proje TalimatlarÄ±nÄ± Ä°ncele (PDF)](docs/reports/Zero2End_ML_Bootcamp_Project_Report.pdf)

## âœ… Proje Gereksinimleri ve KarÅŸÄ±lanma Durumu

Proje talimatlarÄ±nda belirtilen kriterlerin tamamÄ± baÅŸarÄ±yla uygulanmÄ±ÅŸtÄ±r:

| Gereksinim | Durum | Uygulama DetayÄ± |
|------------|-------|-----------------|
| **Veri Analizi (EDA)** | âœ… TamamlandÄ± | Notebook 1'de detaylÄ± veri keÅŸfi ve temizliÄŸi yapÄ±ldÄ±. |
| **Model GeliÅŸtirme** | âœ… TamamlandÄ± | CatBoost (Lojistik & Churn) ve SVD (Ã–neri) modelleri eÄŸitildi. |
| **Pipeline Kurulumu** | âœ… TamamlandÄ± | Veri indirme -> Ä°ÅŸleme -> EÄŸitim -> Tahmin akÄ±ÅŸÄ± otomatize edildi (`ingest.py`). |
| **Deployment** | âœ… TamamlandÄ± | Streamlit kullanarak interaktif dashboard geliÅŸtirildi ve Cloud'a yÃ¼klendi. |
| **Kod Kalitesi** | âœ… TamamlandÄ± | ModÃ¼ler yapÄ± (`src/`), OOP prensipleri ve Docstring kullanÄ±mÄ±. |
| **Raporlama** | âœ… TamamlandÄ± | Readme dosyasÄ± ve Notebook iÃ§i Markdown aÃ§Ä±klamalarÄ± ile sÃ¼reÃ§ dÃ¶kÃ¼mante edildi. |


| **Ana Sayfa (Dashboard)** | **Operasyon Merkezi** |
|:---:|:---:|
| ![Ana Sayfa](docs/assets/img/dashboard_home.png) | ![Operasyon](docs/assets/img/operations_overview.png) |

| **MÃ¼ÅŸteri Sadakati (Retention)** | **Segmentasyon Analizi** |
|:---:|:---:|
| ![Sadakat](docs/assets/img/customer_loyalty_overview.png) | ![Segmentasyon](docs/assets/img/segmentation_overview.png) |

| **Ranking & Trends** | **ÃœrÃ¼n Ã–neri Motoru** |
|:---:|:---:|
| ![Ranking](docs/assets/img/ranking_top_categories_revenue.png) | ![Ã–neri](docs/assets/img/customer_loyalty_recommendations.png) |

---

## Problem & Ã‡Ã¶zÃ¼m

### Problem 1: Teslimat Gecikmesi
**Sorun:** MÃ¼ÅŸteriler sipariÅŸlerin ne zaman geleceÄŸini bilemiyor, gecikmeler ÅŸikayete dÃ¶nÃ¼ÅŸÃ¼yor.  
**Ã‡Ã¶zÃ¼m:** CatBoost modeli ile teslimat sÃ¼resi tahmini (RMSE: 7.60 gÃ¼n)

**Neden Bu YaklaÅŸÄ±m?**
*   Haversine mesafe (satÄ±cÄ±-mÃ¼ÅŸteri arasÄ±) en Ã¶nemli faktÃ¶r
*   SatÄ±cÄ± puanÄ± (review verisi) teslimat performansÄ±yla iliÅŸkili
*   AynÄ± eyalet = daha hÄ±zlÄ± teslimat

### Problem 2: MÃ¼ÅŸteri KaybÄ± (Churn)
**Sorun:** Hangi mÃ¼ÅŸterilerin platformu terk edeceÄŸini Ã¶nceden tahmin edemiyoruz.  
**TanÄ±m Nedir?:** *Churn*, bir mÃ¼ÅŸterinin platformu kullanmayÄ± bÄ±rakmasÄ± (terk etmesi) demektir.  
**Bizdeki KarÅŸÄ±lÄ±ÄŸÄ±:** 90 gÃ¼n boyunca hiÃ§ sipariÅŸ vermeyen mÃ¼ÅŸteri, sistemimiz tarafÄ±ndan **"Churn" (KaybedilmiÅŸ)** olarak etiketlenir.
**Ã‡Ã¶zÃ¼m:** CatBoost Classifier ile bu riski taÅŸÄ±yan mÃ¼ÅŸterileri erkenden tespit etmek.

**Neden Bu YaklaÅŸÄ±m?**
*   Ä°lk yaklaÅŸÄ±mda AUC %100 Ã§Ä±kÄ±yordu - bu data leakage'dÄ± (DÃ¼zeltildi)
*   Cluster'dan tÃ¼retilen target gerÃ§ekÃ§i deÄŸildi
*   GerÃ§ek tanÄ±m: %80.3 Churn Rate (anlamlÄ±)

### Problem 3: MÃ¼ÅŸteri Tek Tip GÃ¶rÃ¼lÃ¼yor
**Sorun:** TÃ¼m mÃ¼ÅŸterilere aynÄ± pazarlama yapÄ±lÄ±yor.  
**Ã‡Ã¶zÃ¼m:** RFM + K-Means ile segmentasyon (5 segment)

---

## Teknoloji Tercihleri

| Teknoloji | Neden? |
|-----------|--------|
| **SQLite** | Local geliÅŸtirme ve taÅŸÄ±nabilirlik iÃ§in ideal (KonfigÃ¼rasyon gerektirmez) |
| **Streamlit** | React ile aylar sÃ¼recek iÅŸi gÃ¼nlere indirir |
| **Docker** | "Benim bilgisayarÄ±mda Ã§alÄ±ÅŸÄ±yordu" problemini Ã§Ã¶zer |
| **Polars** | ETL'de Pandas'tan 10x hÄ±zlÄ± |
| **FastAPI** | Modern, async, otomatik dokÃ¼mantasyon (Backend API) |

---

## Ã–zellikler

### Lojistik Tahmin
*   **RMSE:** 7.60 gÃ¼n
*   **Ã–zellikler:** Mesafe, kargo, fiyat, aÄŸÄ±rlÄ±k, satÄ±cÄ± puanÄ±

### Churn Tahmini
*   **Rate:** %80.3 (Marketplace doÄŸasÄ± gereÄŸi yÃ¼ksek)
*   **TanÄ±m:** 90 gÃ¼n sipariÅŸ yok = Churn

### MÃ¼ÅŸteri Segmentasyonu
*   **5 Segment:** Åampiyonlar, SadÄ±klar, Potansiyeller, Riskli, Uyuyanlar

### Dashboard
*   **5 Sayfa:** Ana Sayfa, Operasyon, MÃ¼ÅŸteri, Segmentasyon, Ranking
*   **ROI SimÃ¼lasyonu:** Kampanya maliyet/getiri analizi

### API
*   **4 Endpoint:** `/predict/delivery`, `/predict/churn`, `/recommend`, `/segments`
*   **GÃ¼venlik:** X-API-KEY korumasÄ±

---

## ğŸš€ Kurulum ve Ã‡alÄ±ÅŸtÄ±rma

Proje hem Yerel (Local) hem de Docker ortamÄ±nda Ã§alÄ±ÅŸacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r.

### Ã–n Gereksinimler
*   Docker & Docker Compose (Ã–nerilen)
*   Git
*   Python 3.10+ (Yerel Ã§alÄ±ÅŸma iÃ§in)

### AdÄ±m 1: Projeyi Ä°ndir
```bash
git clone https://github.com/vamos99/Zero2End-ML-Bootcamp.git
```

### AdÄ±m 2: Python OrtamÄ±nÄ± Kurun (Sadece Yerel Ã‡alÄ±ÅŸma Ä°Ã§in)
Projenin baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± izole etmek iÃ§in sanal ortam kurmanÄ±z Ã¶nerilir:

```bash
# Sanal Ortam OluÅŸtur
python -m venv venv

# Aktif Et (Mac/Linux)
source venv/bin/activate
# Aktif Et (Windows)
# .\venv\Scripts\activate

# KÃ¼tÃ¼phaneleri YÃ¼kle
pip install -r requirements.txt

# Kernel'i Notebook'a TanÄ±t (Ã–NEMLÄ°)
python -m ipykernel install --user --name=venv --display-name "Python (Olist Project)"
```

### AdÄ±m 3: Ortam DeÄŸiÅŸkenlerini Ayarla (.env)
Projenin Ã§alÄ±ÅŸmasÄ± iÃ§in bir `.env` dosyasÄ± oluÅŸturun (Ã–rnek dosyadan kopyalayabilirsiniz). Notebooklar ve Docker bu dosyayÄ± kullanÄ±r.

```bash
# MacOS/Linux
cp .env.example .env
# Windows
copy .env.example .env
```
ArdÄ±ndan `.env` dosyasÄ±nÄ± aÃ§Ä±p **KAGGLE_USERNAME** ve **KAGGLE_KEY** bilgilerinizi ekleyin (Veri indirmek iÃ§in gereklidir).

### AdÄ±m 4: Veri HazÄ±rlÄ±ÄŸÄ± ve Modeller
Proje aÃ§Ä±ldÄ±ÄŸÄ±nda API Ã§alÄ±ÅŸÄ±r (`.pkl` modelleri hazÄ±r gelir). Ancak **Dashboard grafiklerinin** dolmasÄ± iÃ§in geÃ§miÅŸ tahminlerin Ã¼retilmesi gerekir.

**SÄ±rayla Ã‡alÄ±ÅŸtÄ±rÄ±n:**
1.  `notebooks/1_general_eda_and_prep.ipynb`: **(Zorunlu)** VeritabanÄ± boÅŸsa [Kaggle Olist Dataset](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce) verisini indirir ve SQL tablolarÄ±nÄ± kurar.
2.  `notebooks/2_logistics_engine.ipynb`: **(Gerekli)** Dashboard'daki "Operasyon" ekranÄ±nÄ±n dolmasÄ± iÃ§in lojistik tahminlerini veritabanÄ±na yazar.
3.  `notebooks/3_customer_sentinel.ipynb`: **(Gerekli)** Churn modelini eÄŸitir ve analiz eder.
4.  `notebooks/4_growth_engine.ipynb`: **(Gerekli)** Dashboard'daki "MÃ¼ÅŸteri" ekranÄ±nÄ±n dolmasÄ± iÃ§in segmentasyon verilerini veritabanÄ±na yazar.

**Ä°steÄŸe BaÄŸlÄ± Analizler (Opsiyonel):**
*   `notebooks/5_final_evaluation.ipynb`: TÃ¼m modellerin toplu performans karÅŸÄ±laÅŸtÄ±rmasÄ±.
*   `notebooks/6_executive_pipeline.ipynb`: Yeni gelen haftalÄ±k verinin nasÄ±l iÅŸleneceÄŸini simÃ¼le eden pipeline.
*Not: VeritabanÄ± (`olist.db`) bu iÅŸlem sonunda dolacaktÄ±r.*

### SeÃ§enek A: Docker ile BaÅŸlatma (Ã–nerilen)
TÃ¼m servisleri (API, Dashboard, MLflow) tek komutla baÅŸlatÄ±n.

```bash
docker-compose up --build
```

### SeÃ§enek B: HÄ±zlÄ± BaÅŸlangÄ±Ã§ (Script ile)
Tek komutla MLflow, API ve Dashboard'u aynÄ± anda baÅŸlatÄ±n:

```bash
chmod +x run_local.sh
./run_local.sh
```

### SeÃ§enek C: Manuel (AdÄ±m AdÄ±m)
EÄŸer her servisi ayrÄ± terminalde gÃ¶rmek isterseniz:

1. **Terminal 1: MLflow ArayÃ¼zÃ¼ (Zorunlu)**
   ```bash
   mlflow ui --port 5000
   ```
   *(Bunu baÅŸlatmazsanÄ±z API modelleri yÃ¼kleyemez ve aÃ§Ä±lmaz)*

2. **Terminal 2: API**
   ```bash
   uvicorn src.app:app --reload
   ```

3. **Terminal 3: Dashboard**
   ```bash
   streamlit run src/dashboard.py
   ```

---

## Notebook'larÄ± Ã‡alÄ±ÅŸtÄ±rma (GeliÅŸtirme)

Analiz yapmak iÃ§in yerel Python ortamÄ±nÄ±za baÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼klediÄŸinizden emin olun (AdÄ±m 2'deki gibi).
Notebooklar `.env` dosyasÄ±ndaki ayarlarÄ± otomatik okur.

```bash
cd notebooks
jupyter lab
```

---

## Dosya YapÄ±sÄ±

```
src/
â”œâ”€â”€ app.py          # FastAPI Backend
â”œâ”€â”€ dashboard.py    # Streamlit Frontend
â”œâ”€â”€ ml/             # ML Core (EÄŸitim, Ingestion)
â”‚   â”œâ”€â”€ ingest.py   # CSV â†’ SQLite
â”‚   â””â”€â”€ train.py    # Model EÄŸitimi
â”œâ”€â”€ services/       # Ä°ÅŸ MantÄ±ÄŸÄ± (Service Layer)
â”œâ”€â”€ views/          # Dashboard SayfalarÄ±
â””â”€â”€ database/       # VeritabanÄ± BaÄŸlantÄ±sÄ±

notebooks/
â”œâ”€â”€ 1_general_eda_and_prep.ipynb  # Veri keÅŸfi ve YÃ¼kleme
â”œâ”€â”€ 2_logistics_engine.ipynb      # Teslimat modeli eÄŸitimi
â”œâ”€â”€ 3_customer_sentinel.ipynb     # Churn analizi
â”œâ”€â”€ 4_growth_engine.ipynb         # Segmentasyon modeli
â””â”€â”€ ...

data/               # CSV dosyalarÄ± (Git-ignored)
models/             # EÄŸitilmiÅŸ modeller (.pkl)
docs/               # Proje dÃ¶kÃ¼manlarÄ± ve gÃ¶rseller
```

## Model PerformansÄ±

| Model | Algoritma | Metrik | DeÄŸer |
|-------|-----------|--------|-------|
| **Lojistik** | CatBoost Regressor | RMSE | ~7.6 GÃ¼n |
| **Churn** | CatBoost Classifier | Accuracy | ~%90 (Imbalanced) |
| **Recommender** | SVD | Coverage | 99K User |

---

### Troubleshooting (Sorun Giderme)

*   **API BaÄŸlantÄ± HatasÄ±:** MacOS kullanÄ±cÄ±larÄ± `localhost` yerine `127.0.0.1` kullanmalÄ±dÄ±r (Projede varsayÄ±lan olarak ayarlanmÄ±ÅŸtÄ±r).
*   **Grafikler/Tablolar BoÅŸ GÃ¶rÃ¼nÃ¼yor:**
    *   **Durum:** API ve SimÃ¼lasyonlar Ã§alÄ±ÅŸÄ±yor (`.pkl` modelleri hazÄ±r geldiÄŸi iÃ§in).
    *   **Ã‡Ã¶zÃ¼m:** Dashboard'daki *"Operasyon Merkezi"* gibi geÃ§miÅŸe dÃ¶nÃ¼k analizlerin dolmasÄ± iÃ§in veritabanÄ±nda tahmin tablolarÄ±nÄ±n oluÅŸmasÄ± ÅŸarttÄ±r. Bunu saÄŸlamak iÃ§in **Notebook 2 (Lojistik)** ve **Notebook 4 (Churn)** dosyalarÄ±nÄ± bir kez Ã§alÄ±ÅŸtÄ±rmanÄ±z yeterlidir.
*   **Docker Port HatasÄ±:** Yerelde Ã§alÄ±ÅŸan servisleri (`Ctrl+C`) kapatÄ±p `docker-compose`'u yeniden baÅŸlatÄ±n.

---
**Versiyon:** 2.1 | **GÃ¼ncelleme:** AralÄ±k 2025
